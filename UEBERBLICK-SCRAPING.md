# ÃœBERBLICK SCRAPING-SYSTEM

## ğŸ“Š **GROBE ÃœBERSICHT** 

```
npm run scrape-production â†’ Keywords wÃ¤hlen â†’ Reddit durchsuchen â†’ 
Posts filtern â†’ AI Ã¼bersetzt & formatiert â†’ Dateien speichern â†’ 
Review-System â†’ In mock-data.ts integrieren
```

---

## ğŸ”„ **KONKRETE SCHRITTE**

### **Phase 1: Initialisierung**
1. Terminal-Befehl `npm run scrape-production` startet `scripts/scrape-content.ts`
2. LÃ¤dt Production-Config: 50 Tricks max, 70% Confidence, Reddit + Twitter + Hacker News
3. PrÃ¼ft API-Keys (APIFY_API_TOKEN, OPENAI_API_KEY, ANTHROPIC_API_KEY)

### **Phase 2: Scraping**
4. WÃ¤hlt 5 zufÃ¤llige Keywords aus 100 verfÃ¼gbaren
5. Sucht auf Reddit mit diesen Keywords (Twitter/HN noch nicht implementiert)
6. Filtert Posts: Min. 3 Upvotes, 1 Kommentar, >200 Zeichen
7. Bei Fehler: Automatischer Fallback zu 8 Demo-Posts

### **Phase 3: AI-Verarbeitung**
8. Jeder Post wird verarbeitet:
   - Priorisiert OpenAI GPT-4o-mini (gÃ¼nstig)
   - Fallback zu Claude API
   - Notfalls Pattern-Matching
9. Generiert deutschen KI-Trick mit allen Komponenten

### **Phase 4: QualitÃ¤tskontrolle**
10. Duplikat-Check gegen existierende Tricks
11. Confidence-Score Bewertung (min. 70%)
12. Stoppt bei 50 erfolgreichen Tricks

### **Phase 5: Speicherung**
13. Erstellt JSON + TypeScript Dateien in `scraped-content/`
14. Generiert Markdown-Zusammenfassung

### **Phase 6: Review & Integration**
15. Optional: `npm run review-and-append` fÃ¼r manuelle Review
16. Genehmigung einzelner Tricks mit Edit-MÃ¶glichkeit
17. Automatische Integration in `src/lib/data/mock-data.ts`

---

## ğŸ”¬ **SUPER-DETAILLIERTE ROADMAP**

### **ğŸš€ START: npm run scrape-production**

#### **1ï¸âƒ£ Initialisierungs-Phase (0-5 Sekunden)**

**1.1 Script-Start**
- Datei: `scripts/scrape-content.ts`
- LÃ¤dt `.env.local` fÃ¼r API-Keys
- Parst Kommandozeilen-Argumente

**1.2 Konfiguration laden**
```javascript
config = DEFAULT_BATCH_CONFIGS.production = {
  maxTricksPerRun: 50,
  minConfidenceScore: 70,
  outputFormat: 'both',
  dryRun: false,
  useDemo: false,
  platforms: ['reddit', 'twitter', 'hackernews']
}
```

**1.3 API-Key Status-Check**
```
ğŸ”‘ Environment Check:
   APIFY_API_TOKEN: Gesetzt âœ… / Fehlt âŒ
   OPENAI_API_KEY: Gesetzt âœ… / Fehlt âŒ
   ANTHROPIC_API_KEY: Gesetzt âœ… / Fehlt âŒ
```

---

#### **2ï¸âƒ£ Vorbereitung (5-10 Sekunden)**

**2.1 ContentBatchProcessor initialisieren**
- Erstellt RedditScraper-Instanz
- LÃ¤dt existierende Tricks aus `src/lib/data/mock-data.ts`
- Extrahiert ~44 Trick-Titel fÃ¼r Duplikat-Check

**2.2 Keyword-Auswahl**
- Datei: `src/lib/ai/scraping-keywords.ts`
- Funktion: `getBalancedKeywords(5)`
- WÃ¤hlt aus 10 Kategorien mit je 10 Keywords:
  - productivity: "AI productivity hack", "automate tasks with AI"...
  - programming: "ChatGPT tips for developers", "Claude coding tricks"...
  - contentCreation: "AI for content creation", "Midjourney prompt guide"...
  - (7 weitere Kategorien)
- **ZufÃ¤llig 5 Keywords** aus 100 mÃ¶glichen

---

#### **3ï¸âƒ£ Reddit-Scraping (10-30 Sekunden)**

**3.1 Reddit Scraper aktiviert**
```javascript
inputConfig = {
  searches: [5 dynamische Keywords],
  searchPosts: true,
  searchComments: false,
  sort: 'top',
  time: 'month',
  maxItems: 50,
  maxPostCount: 25,
  proxy: { useApifyProxy: true, apifyProxyGroups: ["RESIDENTIAL"] }
}
```

**3.2 Apify Actor Call**
- Actor: `trudax/reddit-scraper-lite`
- Sucht in Reddit nach den 5 Keywords
- Fokus auf Posts (keine Kommentare)
- Zeitraum: Letzter Monat
- Max. 50 Items insgesamt

**3.3 Fallback-Mechanismus**
```
Wenn Apify fehlschlÃ¤gt:
â”œâ”€â”€ Fehlerursachen:
â”‚   â”œâ”€â”€ Kein/Falscher API-Token
â”‚   â”œâ”€â”€ Rate Limits erreicht
â”‚   â””â”€â”€ Actor nicht verfÃ¼gbar
â””â”€â”€ Automatischer Switch zu Demo-Daten (8 hochwertige Beispiel-Posts)
```

---

#### **4ï¸âƒ£ Content-Normalisierung (1-2 Sekunden)**

**4.1 Reddit-Content normalisieren**
```javascript
FÃ¼r jeden Post:
{
  platform: 'reddit',
  title: post.title,
  content: post.body || post.selftext,
  url: post.url,
  score: post.upVotes,        // Reddit-Upvotes
  comments: post.numberOfComments,
  author: post.username,
  createdAt: post.createdAt,
  tags: [subreddit, flair, extrahierte Hashtags]
}
```

**4.2 QualitÃ¤tsfilter**
```
Bedingungen fÃ¼r Behalten:
âœ“ score >= 3 (mindestens 3 Upvotes)
âœ“ comments >= 1 (mindestens 1 Kommentar)
âœ“ content.length > 200 (substantieller Inhalt)
âœ“ AI-Relevanz erkannt (Keywords in Title/Content)
```

---

#### **5ï¸âƒ£ AI-Verarbeitung (30-120 Sekunden)**

**5.1 FÃ¼r jeden gefilterten Post:**

**API-PrioritÃ¤t:**
1. **OpenAI GPT-4o-mini** (wenn OPENAI_API_KEY vorhanden)
   - Kosten: $0.15 per 1M Input-Tokens
   - Schnell und gÃ¼nstig
   
2. **Claude API** (wenn ANTHROPIC_API_KEY vorhanden)
   - Als Backup fÃ¼r OpenAI
   
3. **Pattern-Matching** (wenn keine API verfÃ¼gbar)
   - Regelbasierte Extraktion

**5.2 AI-Prompt-Struktur:**
```xml
Analysiere diesen Reddit-Post und erstelle einen deutschen KI-Trick:

<reddit_post>
[Title und Content]
</reddit_post>

Erstelle folgende Struktur:
<kitrick>
  <title>Catchy deutscher Titel (max 100 Zeichen)</title>
  <description>Beschreibung mit **Warum es funktioniert:** Hook</description>
  <category>productivity|programming|learning|etc</category>
  <difficulty>beginner|intermediate|advanced</difficulty>
  <tools>Claude, ChatGPT, etc</tools>
  <timeToImplement>5-10 Minuten</timeToImplement>
  <impact>low|medium|high</impact>
  <steps>4 konkrete Schritte</steps>
  <examples>2 Real-World Beispiele</examples>
</kitrick>
```

**5.3 Generierte Komponenten:**
- **Titel**: "Der 10-Sekunden Prompt der jeden Code-Fehler debuggt"
- **Psychologie-Hook**: "**Warum es funktioniert:** Nutzt das Prinzip der kognitiven Entlastung..."
- **4 Schritte**: Beginnend mit Aktionsverben
- **2 Beispiele**: Mit messbaren Resultaten
- **Kategorisierung**: Automatisch basierend auf Content
- **Schwierigkeit**: Basierend auf KomplexitÃ¤t
- **ZeitschÃ¤tzung**: "10-15 Minuten", "30-45 Minuten"
- **Impact**: Basierend auf potenziellem Nutzen

---

#### **6ï¸âƒ£ QualitÃ¤tskontrolle (1 Sekunde pro Trick)**

**6.1 Duplikat-Check**
```javascript
Vergleicht mit ~44 existierenden Tricks:
â”œâ”€â”€ Exakter Titel-Match â†’ Skip
â”œâ”€â”€ Ã„hnlichkeit > 80% â†’ Skip
â””â”€â”€ Neu â†’ Weiter
```

**6.2 Confidence-Score**
```javascript
Berechnung (0-100%):
â”œâ”€â”€ Hat Psychologie-Hook: +20
â”œâ”€â”€ Konkrete Zeitangabe: +10
â”œâ”€â”€ Steps mit Verben: +10
â”œâ”€â”€ Beispiele mit Zahlen: +20
â”œâ”€â”€ 1-3 Tools: +10
â”œâ”€â”€ Gute LÃ¤nge (200-500): +10
â”œâ”€â”€ High Impact: +20
â””â”€â”€ Minimum fÃ¼r Production: 70%
```

**6.3 Limit-Check**
```
Nach jedem erfolgreichen Trick:
if (newTricks.length >= 50) {
  console.log("ğŸ¯ Limit von 50 Tricks erreicht");
  break;
}
```

---

#### **7ï¸âƒ£ Speicherung (2-5 Sekunden)**

**7.1 Datei-Erstellung**
```
Ordner: scraped-content/
â”œâ”€â”€ kitricks-2025-08-06_14-30-15.json (JSON-Format)
â”œâ”€â”€ kitricks-2025-08-06_14-30-15.ts (TypeScript-Export)
â””â”€â”€ summary-2025-08-06_14-30-15.md (Zusammenfassung)
```

**7.2 JSON-Format**
```json
[{
  "id": "scraped-1754348175143-e59b2h1xz",
  "title": "Der ultimative ChatGPT Prompt",
  "description": "...\n\n**Warum es funktioniert:**...",
  "category": "productivity",
  "difficulty": "beginner",
  "tools": ["ChatGPT", "Claude"],
  "timeToImplement": "10-15 Minuten",
  "impact": "high",
  "steps": ["Schritt 1...", "..."],
  "examples": ["Beispiel 1...", "..."],
  "slug": "der-ultimative-chatgpt-prompt",
  "createdAt": "2025-08-06T14:30:15Z",
  "updatedAt": "2025-08-06T14:30:15Z"
}]
```

**7.3 Zusammenfassung**
```markdown
# KI-Tricks Scraping Zusammenfassung

**Datum:** 6.8.2025, 14:30:15
**Gesamt:** 23 neue KI-Tricks
**Verarbeitet:** 50 Posts
**Ãœbersprungen:** 27 (15 Duplikate, 12 Low-Quality)

## Kategorien
- productivity: 8
- programming: 6
- learning: 5
- business: 4

## Top Tricks (nach Impact)
1. Der 10-Sekunden Debug-Prompt (programming)
2. Meetings in Tasks verwandeln (productivity)
[...]
```

---

#### **8ï¸âƒ£ Abschluss & Review (Optional)**

**8.1 Erfolgsmeldung**
```
âœ… 23 neue KI-Tricks erfolgreich erstellt!

ğŸ¯ NÃ„CHSTE SCHRITTE:
1. PrÃ¼fe die erstellten Dateien im scraped-content/ Verzeichnis
2. Reviewe die Tricks manuell auf QualitÃ¤t
3. Integriere gewÃ¼nschte Tricks in mock-data.ts
4. Teste die neuen Tricks auf der Website
```

**8.2 Review-System (npm run review-and-append)**
```
FÃ¼r jeden Trick:
â”œâ”€â”€ Zeigt Trick-Details
â”œâ”€â”€ Optionen:
â”‚   â”œâ”€â”€ y: Genehmigen
â”‚   â”œâ”€â”€ n: Ãœberspringen
â”‚   â””â”€â”€ e: Editieren (Ã¶ffnet VS Code)
â””â”€â”€ Genehmigte Tricks â†’ Automatisch in mock-data.ts eingefÃ¼gt
```

---

### **â±ï¸ ZEITLICHE ÃœBERSICHT**

| Phase | Dauer | Beschreibung |
|-------|-------|--------------|
| Initialisierung | 0-5 Sek | Config laden, API-Keys prÃ¼fen |
| Vorbereitung | 5-10 Sek | Existierende Tricks laden, Keywords wÃ¤hlen |
| Scraping | 10-30 Sek | Reddit durchsuchen (oder Demo-Daten) |
| AI-Verarbeitung | 30-120 Sek | 50 Posts â†’ KI-Tricks konvertieren |
| QualitÃ¤tskontrolle | 5-10 Sek | Duplikate filtern, Confidence prÃ¼fen |
| Speicherung | 2-5 Sek | JSON/TS/MD Dateien erstellen |
| **GESAMT** | **~1-3 Minuten** | **FÃ¼r 20-50 neue Tricks** |

---

### **ğŸ¯ ENDE: Integration in mock-data.ts**

Die neuen Tricks sind jetzt bereit fÃ¼r die Website und werden beim nÃ¤chsten Build automatisch angezeigt!